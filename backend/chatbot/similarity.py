"""
Module de recherche FAQ - VERSION SIMPLIFIÃ‰E v2.1
ConÃ§u pour 6500+ FAQs avec 1GB RAM (Railway: 1 worker, 2 threads)

ARCHITECTURE SIMPLIFIÃ‰E (3 NIVEAUX):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

NIVEAU 0: RÃˆGLES CONVERSATIONNELLES (JSON externe)
    âœ“ Pattern matching simple, AVANT vectorisation
    âœ“ RÃ¨gles chargÃ©es depuis conversational_rules.json
    âœ“ Performance: <5ms, RAM: 0 MB
    âœ“ RÃ©sout: ~30% des requÃªtes

NIVEAU 1: CATÃ‰GORIES PAR POPULARITÃ‰ + CACHE
    âœ“ Traite catÃ©gories par ordre de popularitÃ© dÃ©croissante
    âœ“ 1 catÃ©gorie Ã  la fois (Ã©conomise RAM)
    âœ“ Cache: derniÃ¨re catÃ©gorie avec meilleur score
    âœ“ Commence par cache, puis catÃ©gories populaires
    âœ“ Stop dÃ¨s que score d'une catÃ©gorie = 0 (plus rien Ã  trouver)
    âœ“ Performance: <2s, RAM: 40-60 MB
    âœ“ RÃ©sout: ~60% des requÃªtes

NIVEAU 2: FALLBACK GLOBAL
    âœ“ Si aucune catÃ©gorie n'a donnÃ© de rÃ©sultat
    âœ“ Scan toutes catÃ©gories (batch de 3)
    âœ“ Performance: <5s, RAM: 60-80 MB
    âœ“ RÃ©sout: ~10% des requÃªtes

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import numpy as np
import json
from pathlib import Path
from django.db import models
from django.db.models import Count, Sum
from faq.models import FAQ, FAQVector, Category
from chatbot.vectorization import compute_tfidf_vector
from typing import List, Dict, Tuple, Optional


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURATION GLOBALE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Chemin du fichier JSON des rÃ¨gles conversationnelles
RULES_JSON_PATH = Path(__file__).parent.parent / 'data' / 'json' / 'conversational_rules.json'

# Seuil pour considÃ©rer un score comme bon
GOOD_SCORE_THRESHOLD = 0.7

# Cache global: derniÃ¨re catÃ©gorie avec meilleur score
_CATEGORY_CACHE = {
    'category_id': None,
    'category_name': None,
    'last_score': 0.0
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CHARGEMENT RÃˆGLES CONVERSATIONNELLES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_conversational_rules():
    """
    Charger les rÃ¨gles conversationnelles depuis le fichier JSON.
    
    Returns:
        list: Liste de rÃ¨gles {'intent', 'patterns', 'response'}
    """
    try:
        if RULES_JSON_PATH.exists():
            with open(RULES_JSON_PATH, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('conversational_rules', [])
        else:
            print(f"[Similarity] âš ï¸ Fichier de rÃ¨gles non trouvÃ©: {RULES_JSON_PATH}")
            return []
    except Exception as e:
        print(f"[Similarity] âš ï¸ Erreur chargement rÃ¨gles: {e}")
        return []


# Charger les rÃ¨gles au dÃ©marrage du module
CONVERSATIONAL_RULES = load_conversational_rules()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# UTILITAIRES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def compute_similarity_batch(user_vec: np.ndarray, 
                             user_norm: float,
                             faq_vectors: List) -> List[Tuple[FAQ, float]]:
    """
    Calculer les similaritÃ©s cosinus pour un batch de FAQVectors.
    
    Args:
        user_vec: Vecteur TF-IDF de la question utilisateur
        user_norm: Norme du vecteur utilisateur
        faq_vectors: Liste de FAQVector objects
    
    Returns:
        List de tuples (FAQ, score) triÃ©s par score dÃ©croissant
    """
    if not faq_vectors or user_norm == 0:
        return []
    
    # Construire matrice de vecteurs FAQ
    faqs = []
    norms = []
    vectors = []
    
    for faq_vec in faq_vectors:
        faqs.append(faq_vec.faq)
        norms.append(faq_vec.norm)
        vectors.append(faq_vec.tfidf_vector)
    
    # Conversion en numpy arrays (float32 pour Ã©conomiser RAM)
    faq_matrix = np.array(vectors, dtype=np.float32)
    faq_norms = np.array(norms, dtype=np.float32)
    user_vec_f32 = user_vec.astype(np.float32)
    
    # Calcul vectorisÃ© des similaritÃ©s cosinus
    dot_products = faq_matrix @ user_vec_f32
    scores = dot_products / (faq_norms * user_norm)
    scores = np.clip(scores, 0.0, 1.0)
    
    # CrÃ©er liste de rÃ©sultats
    results = [(faqs[i], float(scores[i])) for i in range(len(faqs))]
    
    # Trier par score dÃ©croissant
    results.sort(key=lambda x: x[1], reverse=True)
    
    # LibÃ©rer mÃ©moire explicitement
    del faq_matrix, faq_norms, vectors, scores, dot_products
    
    return results


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NIVEAU 0: RÃˆGLES CONVERSATIONNELLES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def match_conversational_rule(question: str) -> Optional[str]:
    """
    NIVEAU 0: Matcher une question contre les rÃ¨gles conversationnelles.
    
    Args:
        question (str): Question de l'utilisateur
    
    Returns:
        str: RÃ©ponse directe si match trouvÃ©, None sinon
    """
    question_lower = question.lower().strip()
    
    # Chercher un match dans chaque rÃ¨gle
    for rule in CONVERSATIONAL_RULES:
        intent = rule.get('intent', 'unknown')
        patterns = rule.get('patterns', [])
        response = rule.get('response', '')
        
        for pattern in patterns:
            if pattern in question_lower:
                print(f"[Similarity L0] âœ… RÃˆGLE '{intent}' (pattern: '{pattern}')")
                return response
    
    return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NIVEAU 1: CATÃ‰GORIES PAR POPULARITÃ‰ + CACHE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_categories_by_popularity():
    """
    RÃ©cupÃ©rer les catÃ©gories triÃ©es par popularitÃ© dÃ©croissante.
    
    Returns:
        List[Category]: CatÃ©gories triÃ©es
    """
    # Calculer popularitÃ© totale par catÃ©gorie
    categories = Category.objects.filter(active=True).annotate(
        total_popularity=Sum('faq__popularity'),
        faq_count=Count('faq', filter=models.Q(faq__is_active=True))
    ).filter(faq_count__gt=0).order_by('-total_popularity')
    
    return list(categories)


def search_in_category(category: Category, user_vec: np.ndarray, user_norm: float,
                      top_k: int = 3) -> Tuple[List[Tuple[FAQ, float]], float]:
    """
    Rechercher dans une catÃ©gorie spÃ©cifique.
    
    Args:
        category: CatÃ©gorie Ã  explorer
        user_vec: Vecteur utilisateur
        user_norm: Norme du vecteur
        top_k: Nombre de rÃ©sultats
    
    Returns:
        Tuple de (rÃ©sultats, meilleur_score)
    """
    # RÃ©cupÃ©rer vecteurs de cette catÃ©gorie
    category_vectors = FAQVector.objects.filter(
        faq__category=category,
        faq__is_active=True
    ).select_related('faq').only(
        'tfidf_vector', 'norm',
        'faq__id', 'faq__question', 'faq__answer', 'faq__popularity'
    )
    
    if not category_vectors.exists():
        return [], 0.0
    
    # Calcul des similaritÃ©s
    results = compute_similarity_batch(user_vec, user_norm, list(category_vectors))
    
    if not results:
        return [], 0.0
    
    best_score = results[0][1]
    return results[:top_k], best_score


def search_by_popularity_with_cache(user_vec: np.ndarray, user_norm: float,
                                    top_k: int = 3) -> Optional[List[Dict]]:
    """
    NIVEAU 1: Recherche par catÃ©gories populaires avec cache.
    
    Processus:
    1. Si cache existe â†’ chercher d'abord dans catÃ©gorie cachÃ©e
    2. Chercher dans catÃ©gories par ordre de popularitÃ© (1 par 1)
    3. Stop dÃ¨s que score d'une catÃ©gorie = 0 (plus rien Ã  trouver)
    4. Mettre Ã  jour cache avec catÃ©gorie ayant meilleur score
    
    Args:
        user_vec: Vecteur TF-IDF
        user_norm: Norme du vecteur
        top_k (int): Nombre de rÃ©sultats
    
    Returns:
        Liste de rÃ©sultats si trouvÃ©, None sinon
    """
    global _CATEGORY_CACHE
    
    print(f"[Similarity L1] ğŸ” Recherche par catÃ©gories populaires...")
    
    best_results = None
    best_score = 0.0
    best_category = None
    
    # Liste des catÃ©gories Ã  traiter
    categories = get_categories_by_popularity()
    
    if not categories:
        print("[Similarity L1] âš ï¸ Aucune catÃ©gorie active trouvÃ©e")
        return None
    
    # 1. D'ABORD: VÃ©rifier le cache
    if _CATEGORY_CACHE['category_id']:
        print(f"[Similarity L1] ğŸ“¦ VÃ©rification cache: '{_CATEGORY_CACHE['category_name']}'")
        
        try:
            cached_category = Category.objects.get(id=_CATEGORY_CACHE['category_id'])
            results, score = search_in_category(cached_category, user_vec, user_norm, top_k)
            
            if score > 0:
                print(f"[Similarity L1] ğŸ“ˆ Cache: score={score:.3f}")
                best_results = results
                best_score = score
                best_category = cached_category
                
                # Si excellent score â†’ retour immÃ©diat
                if score >= GOOD_SCORE_THRESHOLD:
                    print(f"[Similarity L1] âœ… TROUVÃ‰ dans cache (score â‰¥ {GOOD_SCORE_THRESHOLD})")
                    return [{'faq': faq, 'score': s} for faq, s in best_results]
        
        except Category.DoesNotExist:
            print("[Similarity L1] âš ï¸ CatÃ©gorie en cache n'existe plus")
            _CATEGORY_CACHE = {'category_id': None, 'category_name': None, 'last_score': 0.0}
    
    # 2. ENSUITE: Parcourir catÃ©gories par popularitÃ©
    print(f"[Similarity L1] ğŸ“Š Traitement de {len(categories)} catÃ©gories...")
    
    for category in categories:
        # Skip si c'est la catÃ©gorie dÃ©jÃ  testÃ©e en cache
        if _CATEGORY_CACHE['category_id'] == category.id:
            continue
        
        print(f"[Similarity L1] ğŸ” CatÃ©gorie: '{category.name}'")
        
        results, score = search_in_category(category, user_vec, user_norm, top_k)
        
        if score == 0:
            print(f"[Similarity L1] âš ï¸ Score nul pour '{category.name}' â†’ STOP recherche")
            break  # Plus rien Ã  trouver dans les catÃ©gories suivantes
        
        print(f"[Similarity L1] ğŸ“ˆ Score: {score:.3f}")
        
        if score > best_score:
            best_results = results
            best_score = score
            best_category = category
            
            # Si excellent score â†’ retour immÃ©diat
            if score >= GOOD_SCORE_THRESHOLD:
                print(f"[Similarity L1] âœ… TROUVÃ‰ (score â‰¥ {GOOD_SCORE_THRESHOLD})")
                break
    
    # 3. Mettre Ã  jour le cache
    if best_category:
        _CATEGORY_CACHE = {
            'category_id': best_category.id,
            'category_name': best_category.name,
            'last_score': best_score
        }
        print(f"[Similarity L1] ğŸ’¾ Cache mis Ã  jour: '{best_category.name}' (score: {best_score:.3f})")
    
    # 4. Retourner meilleur rÃ©sultat trouvÃ©
    if best_results and best_score > 0:
        print(f"[Similarity L1] âœ… Meilleur rÃ©sultat: {best_score:.3f} dans '{best_category.name}'")
        return [{'faq': faq, 'score': s} for faq, s in best_results]
    
    print("[Similarity L1] âŒ Aucun rÃ©sultat trouvÃ©")
    return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NIVEAU 2: FALLBACK GLOBAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def search_fallback_global(user_vec: np.ndarray, user_norm: float,
                          top_k: int = 3) -> List[Dict]:
    """
    NIVEAU 2: Fallback - recherche dans TOUTES les catÃ©gories.
    
    Args:
        user_vec: Vecteur TF-IDF
        user_norm: Norme du vecteur
        top_k (int): Nombre de rÃ©sultats
    
    Returns:
        Liste de rÃ©sultats (meilleur score global)
    """
    print(f"[Similarity L2] ğŸ” Fallback global...")
    
    # RÃ©cupÃ©rer TOUS les vecteurs actifs (toutes catÃ©gories)
    all_vectors = FAQVector.objects.filter(
        faq__is_active=True
    ).select_related('faq', 'faq__category').only(
        'tfidf_vector', 'norm',
        'faq__id', 'faq__question', 'faq__answer', 'faq__category__name'
    )
    
    if not all_vectors.exists():
        print("[Similarity L2] âš ï¸ Aucune FAQ active")
        return []
    
    print(f"[Similarity L2] ğŸ“Š Recherche dans {all_vectors.count()} FAQs...")
    
    # Calcul des similaritÃ©s sur TOUT le corpus (par batch pour RAM)
    batch_size = 500
    best_results = []
    best_score = 0.0
    
    total = all_vectors.count()
    for i in range(0, total, batch_size):
        batch = list(all_vectors[i:i+batch_size])
        results = compute_similarity_batch(user_vec, user_norm, batch)
        
        if results and results[0][1] > best_score:
            best_results = results[:top_k]
            best_score = results[0][1]
    
    if best_results:
        print(f"[Similarity L2] âœ… Meilleur score global: {best_score:.3f}")
        return [{'faq': faq, 'score': s} for faq, s in best_results]
    
    print("[Similarity L2] âŒ Aucun rÃ©sultat trouvÃ©")
    return []


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FONCTION PRINCIPALE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def find_best_faq(question: str, top_k: int = 3, min_score: float = 0.0) -> List[Dict]:
    """
    Fonction principale de recherche FAQ - Architecture simplifiÃ©e.
    
    Processus:
    0. NIVEAU 0: RÃ¨gles conversationnelles (JSON)
    1. NIVEAU 1: CatÃ©gories par popularitÃ© + cache
    2. NIVEAU 2: Fallback global (si nÃ©cessaire)
    
    Args:
        question (str): Question de l'utilisateur
        top_k (int): Nombre de rÃ©sultats Ã  retourner (dÃ©faut: 3)
        min_score (float): Score minimum pour inclure un rÃ©sultat (dÃ©faut: 0.0)
    
    Returns:
        List[Dict]: Liste de {'faq': FAQ, 'score': float}
    """
    print("=" * 70)
    print(f"[Similarity] ğŸš€ RECHERCHE - '{question[:50]}...'")
    print("=" * 70)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # NIVEAU 0: RÃˆGLES CONVERSATIONNELLES
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("[Similarity L0] ğŸ” VÃ©rification rÃ¨gles...")
    
    direct_response = match_conversational_rule(question)
    
    if direct_response:
        print("[Similarity L0] âœ… RÃ‰PONSE DIRECTE")
        print("=" * 70)
        
        # FAQ virtuelle pour compatibilitÃ©
        virtual_faq = type('VirtualFAQ', (), {
            'id': 0,
            'question': question,
            'answer': direct_response,
            'category': type('Category', (), {'name': 'conversationnel'})(),
            'popularity': 999
        })()
        
        return [{'faq': virtual_faq, 'score': 1.0}]
    
    print("[Similarity L0] âš ï¸ Aucune rÃ¨gle ne correspond")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # VECTORISATION
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("[Similarity] ğŸ”¢ Vectorisation...")
    user_vec, user_norm = compute_tfidf_vector(question)
    
    if user_norm == 0:
        print("[Similarity] âš ï¸ Vecteur nul (mots inconnus)")
        print("=" * 70)
        
        virtual_faq = type('VirtualFAQ', (), {
            'id': 0,
            'question': question,
            'answer': "Je n'ai pas compris votre question. Pouvez-vous la reformuler avec plus de dÃ©tails ?",
            'category': type('Category', (), {'name': 'systÃ¨me'})(),
            'popularity': 0
        })()
        
        return [{'faq': virtual_faq, 'score': 0.0}]
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # NIVEAU 1: CATÃ‰GORIES PAR POPULARITÃ‰ + CACHE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    results = search_by_popularity_with_cache(user_vec, user_norm, top_k)
    
    if results:
        print("[Similarity] âœ… TROUVÃ‰ AU NIVEAU 1")
        print("=" * 70)
        return [r for r in results if r['score'] >= min_score]
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # NIVEAU 2: FALLBACK GLOBAL
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("[Similarity] âš¡ NIVEAU 2 (Fallback)...")
    results = search_fallback_global(user_vec, user_norm, top_k)
    
    print("[Similarity] âœ… RECHERCHE TERMINÃ‰E")
    print("=" * 70)
    
    return [r for r in results if r['score'] >= min_score]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# COMPATIBILITÃ‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def compute_cosine_similarity(vec1, vec2):
    """Fonction de compatibilitÃ© avec ancien code."""
    vec1 = np.asarray(vec1, dtype=np.float32)
    vec2 = np.asarray(vec2, dtype=np.float32)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    if norm1 == 0 or norm2 == 0:
        return 0.0
    score = float(np.dot(vec1, vec2) / (norm1 * norm2))
    return max(0.0, min(1.0, score))
